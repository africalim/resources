{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D Imaging\n",
    "\n",
    "Imagine that we live in 2D universe (so 1D sky) and there are three point sources in the sky at locations $[l_1, l_2, l_3]$ all with the same flux of one. Now nature is continuous (at least at the scales we are probing) so we can simulate the visibilities according to a continuous Fourier transform i.e.\n",
    "\n",
    "$$ V_{pq}(u) = \\int I(l) \\exp(-2\\pi\\imath ul) dl.  $$\n",
    "\n",
    "For our sky consisting of three sources we have\n",
    "\n",
    "$$ V_{pq} = \\int \\left(\\delta(l - l_1) + \\delta(l - l_2) + \\delta(l - l_3)\\right) \\exp(-2\\pi\\imath ul) dl.  $$\n",
    "\n",
    "Write a function that takes the locations of the three point sources as input and returns the visibility evaluated at $u$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visf(u, loc1, loc2, loc3):\n",
    "    return np.exp(-2j*np.pi * u * loc1) + np.exp(-2j*np.pi * u * loc2) + np.exp(-2j*np.pi * u * loc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now assume you have a fictitous interferometer that measurements at uniformly random distributed locations between $u \\in [-u_{max}, u_{max}] $. Choose some source locations and a value of $u_{max}$ and generate some visibilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc1 = -0.1\n",
    "loc2 = 0.1\n",
    "loc3 = 0.2\n",
    "nrow = 50\n",
    "umax = 50.0\n",
    "np.random.seed(42)\n",
    "u = -umax + np.random.random(nrow) * 2 * umax\n",
    "vis = visf(u, loc1, loc2, loc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to set up a discrete version of this operator that can be implemented as a matrix multiplication. To do so we need to set the cell size and number of pixels. Recall that, by the Nyquist criterion, we need to sample at twice the longest frequency present in the spectrum. This tells us how to set the maximum cell size. Since we have chosen the source locations ourselves, we know the required field of view and can use to determine the number of pixels that are required. We do this in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = 1.0/(2*umax)  # Nyquist cell size\n",
    "cell /= 2.0\n",
    "fov = 0.5\n",
    "npix = int(np.ceil(fov/cell))\n",
    "if npix%2:  # make sure it is even\n",
    "    npix += 1\n",
    "print(f'npix = {npix}')\n",
    "l = -fov/2 + np.arange(npix)*cell\n",
    "R = np.zeros((nrow, npix), dtype=np.complex128)\n",
    "for k in range(nrow):\n",
    "    for i in range(npix):\n",
    "        R[k, i] = np.exp(-2j*np.pi * u[k] * l[i])\n",
    "\n",
    "print(np.linalg.matrix_rank(R))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create an \"image\" from these noise free \"visibilities\" we write down the likelihood as\n",
    "\n",
    "$$ \\chi^2 = (y - Rx)^\\dagger N^{-1} (y - Rx),  $$\n",
    "\n",
    "where $y$ is just the vector of \"visibilities\" and $x$ is the image we are after. Taking the gradient and setting it to zero we find\n",
    "\n",
    "$$ R^\\dagger N^{-1} R x = R^\\dagger N^{-1} y ~~ \\equiv ~~ I^D = I^{psf} \\star x  $$\n",
    "\n",
    "The right hand side of this expression is known as the dirty image. We can compute it by applying the adjoint (conjugate transpose) of the above matrix to the visibilities. For now we assume that $N$ is the identity, we will see how this choice affects things later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1.0  # noise level\n",
    "Ninv = np.eye(nrow)/sigma**2\n",
    "wsum = np.sum(np.diag(Ninv))  # sum of the weights\n",
    "ID = (R.conj().T.dot(Ninv.dot(vis))).real\n",
    "plt.plot(l, ID)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take note of the values on the y-axis. Can you explain what you are seeing? What about if you divide the dirty image by the sum of the weights?\n",
    "\n",
    "Recall that the left hand side of the above expression (the Hessian) is an operator that implements convolution with the PSF where the PSF is defined as\n",
    "\n",
    "$$ I^{psf} = R^\\dagger N^{-1} R \\delta_{l_0},  $$\n",
    "\n",
    "\n",
    "where $\\delta_{l_0}$ is a sky vector containing a point source at $l=0$. We can therefore compute the PSF as (why?)\n",
    "\n",
    "$$ I^{psf} = R^\\dagger diag(N^{-1}).  $$\n",
    "\n",
    "Let's compute it and see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.diag(Ninv)\n",
    "PSF = R.conj().T.dot(W).real\n",
    "\n",
    "plt.plot(l, PSF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compute the operator that implements a convolution with the PSF by explicitly constructing the matrix $R^\\dagger N^{-1} R$. In this example the sources have been chosen to lie exacty at pixel locations so we can also create a vector containing the true model $x$. Let us do so below and apply our convolution operator to make sure we get the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsky = np.zeros(npix, dtype=float)\n",
    "pixloc1 = np.where(np.abs(l - loc1) < 1e-10)\n",
    "pixloc2 = np.where(np.abs(l - loc2) < 1e-10)\n",
    "pixloc3 = np.where(np.abs(l - loc3) < 1e-10)\n",
    "xsky[pixloc1] = 1.0\n",
    "xsky[pixloc2] = 1.0\n",
    "xsky[pixloc3] = 1.0\n",
    "\n",
    "PSFc = R.conj().T.dot(Ninv.dot(R))\n",
    "ID2 = PSFc.dot(xsky).real\n",
    "plt.plot(l, ID2)\n",
    "print(np.abs(ID - ID2).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now confirm that this is indeed a convolution by computing the same thing using the FFT. In order for this to work we need to construct the PSF on a grid twice the size of the image (why?). \n",
    "\n",
    "So what we are trying to show is that\n",
    "\n",
    "$$ R^\\dagger N^{-1} R = Z^\\dagger F^\\dagger \\hat{I}^{PSF} F Z, $$\n",
    "\n",
    "where $Z$ is the zero padding operator, $F$ is the FFT and $\\hat{I}^{PSF}$ is the FFT of the PSF computed on a grid twice the size of the image. \n",
    "\n",
    "We start by computing the PSF. We'll need to define a version of $R$ which maps a double sized image to visibilities. We do this in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpsf = -fov + np.arange(2*npix)*cell\n",
    "\n",
    "Rpsf = np.zeros((nrow, 2*npix), dtype=np.complex128)\n",
    "for k in range(nrow):\n",
    "    for i in range(2*npix):\n",
    "        Rpsf[k, i] = np.exp(-2j*np.pi * u[k] * lpsf[i])\n",
    "\n",
    "PSF2 = (Rpsf.conj().T.dot(W)).real\n",
    "plt.plot(lpsf, PSF2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's create a function that implements a convolution with this double sized PSF and confirm that we get the same result when applying it to our sky vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psf_convolve(PSF, x):\n",
    "    npix = x.size\n",
    "    xpad = np.pad(x, (0, npix), mode='constant')\n",
    "    xhat = np.fft.fft(xpad)\n",
    "    PSFhat = np.fft.fft(np.fft.ifftshift(PSF))\n",
    "    xhat *= PSFhat\n",
    "    return np.fft.ifft(xhat)[0:npix].real\n",
    "\n",
    "ID3 = psf_convolve(PSF2, xsky)\n",
    "plt.plot(l, ID3)\n",
    "print(np.abs(ID - ID3).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us inspect the form of the operator $R^\\dagger N^{-1} R$ by explicitly computing it. Do you recognize the structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = (R.conj().T.dot(Ninv.dot(R))).real\n",
    "plt.imshow(H)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D Deconvolution\n",
    "\n",
    "First, let us attempt to reconstruct the true sky by solving the gradient equation above and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linalg.solve(H, ID).real\n",
    "\n",
    "plt.plot(l, x, 'kx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we use the pseudo-inverse instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hpinv = np.linalg.pinv(H)\n",
    "xp = Hpinv.dot(ID).real\n",
    "\n",
    "plt.plot(l, xp, 'kx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us generate some noise and see what happens if we try the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = vis + sigma * np.random.randn(nrow)\n",
    "\n",
    "IDn = R.conj().T.dot(Ninv.dot(d)).real\n",
    "xn = np.linalg.solve(H, IDn).real\n",
    "\n",
    "plt.plot(l, xn, 'kx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with the pseudo-inverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpn = Hpinv.dot(IDn).real\n",
    "plt.plot(l, xpn, 'kx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noise clearly makes the inversion unstable. We need an algorithm that implements some kind of regularisation. Let's start with CLEAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(ID, PSF, gamma=0.1, threshold=0.1, maxit=5000):\n",
    "    '''\n",
    "    1D Hogbom CLEAN \n",
    "    '''\n",
    "    nx = ID.size\n",
    "    nx_psf = PSF.size\n",
    "    assert nx_psf//2 == nx\n",
    "    wsum = PSF.max()\n",
    "    PSF /= wsum\n",
    "    ID /= wsum\n",
    "    Isearch = np.abs(ID)\n",
    "    p = Isearch.argmax()\n",
    "    Imax = Isearch[p]\n",
    "    IR = ID.copy()\n",
    "    IM = np.zeros(nx)\n",
    "    k = 0\n",
    "    while (k < maxit) and (Imax > threshold):\n",
    "        # update model\n",
    "        IM[p] += IR[p] * gamma\n",
    "        \n",
    "        # subtract PSF centered at component\n",
    "        IR -= PSF[nx - p:nx + nx - p] * IR[p] * gamma\n",
    "        \n",
    "        # find new peak\n",
    "        Isearch = np.abs(IR)\n",
    "        p = Isearch.argmax()\n",
    "        Imax = Isearch[p]\n",
    "\n",
    "    if k == maxit:\n",
    "        print('Warning - max iters reached')\n",
    "\n",
    "    return IM, IR\n",
    "\n",
    "\n",
    "\n",
    "model_clean, residual_clean = clean(IDn.copy(), PSF2.copy())\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "ax[0].plot(l, model_clean, 'kx')\n",
    "ax[1].plot(l, residual_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for some Tikhonov regularisation obtained by solving\n",
    "\n",
    "$$ x = (R^\\dagger N^{-1} R + \\eta I)^{-1} I^D,  $$\n",
    "\n",
    "where $\\eta > 0$ is some small positive number used to regularise the problem and $I$ here denotes the identity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.001\n",
    "model_tikhonov = np.linalg.solve(H + eta*np.eye(npix), IDn)\n",
    "residual_tikhonov = IDn - H.dot(model_tikhonov)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "ax[0].plot(l, model_tikhonov, 'kx')\n",
    "ax[1].plot(l, residual_tikhonov/wsum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about some sparsity? Because we know where the sources are, we can cheat and solve for their fluxes at pixel locations only, implicitly setting all other pixels to zero. We can do this by modifying our measurement operator as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsparse = np.array([loc1, loc2, loc3])\n",
    "Rs = np.zeros((nrow, 3), dtype=np.complex128)\n",
    "for k in range(nrow):\n",
    "    for i in range(3):\n",
    "        Rs[k, i] = np.exp(-2j*np.pi * u[k] * lsparse[i])\n",
    "\n",
    "IDs = Rs.conj().T.dot(Ninv.dot(d)).real\n",
    "Hs = Rs.conj().T.dot(Ninv.dot(Rs)).real\n",
    "Is = np.linalg.solve(Hs, IDs)\n",
    "\n",
    "print(Is.sum())\n",
    "\n",
    "model_sparse = np.zeros(npix)\n",
    "model_sparse[pixloc1] = Is[0]\n",
    "model_sparse[pixloc2] = Is[1]\n",
    "model_sparse[pixloc3] = Is[2]\n",
    "residual_sparse = IDn - H.dot(model_sparse)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "ax[0].plot(l, model_sparse, 'kx')\n",
    "ax[1].plot(l, residual_sparse/wsum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
